{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ef2db4",
   "metadata": {},
   "source": [
    "\n",
    "# ðŸ“˜ Image Processing & Analysis Toolkit \n",
    "\n",
    "This notebook explains, block-by-block, how the provided **Streamlit + OpenCV** application works, and demonstrates the core image-processing operations (color conversions, transformations, filtering, morphology, enhancement, and edge detection) on sample images.\n",
    "\n",
    "> You can **run this notebook** to understand the pipeline and preview each operation locally. For the **GUI**, run the Streamlit app with:\n",
    "```bash\n",
    "python -m streamlit run app.py\n",
    "```\n",
    "(Replace `app.py` with your actual filename if different.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23e1122",
   "metadata": {},
   "source": [
    "\n",
    "## 1) Project Structure & Dependencies\n",
    "\n",
    "**Key files** (suggested):\n",
    "```\n",
    "/your-project/\n",
    "â”œâ”€â”€ app.py                          # Streamlit GUI (your provided script)\n",
    "â”œâ”€â”€ requirements.txt                # streamlit, opencv-python, numpy, pillow, matplotlib\n",
    "â””â”€â”€ notebooks/\n",
    "    â””â”€â”€ Image_Processing_Toolkit_Explained.ipynb\n",
    "```\n",
    "\n",
    "**Install dependencies** (one-time):\n",
    "```bash\n",
    "pip install streamlit opencv-python numpy pillow matplotlib\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17328795",
   "metadata": {},
   "source": [
    "\n",
    "## 2) High-Level Architecture\n",
    "\n",
    "- **Input Layer**: Upload image via Streamlit (`st.file_uploader`) or capture frames from webcam.\n",
    "- **Processing Core (OpenCV + NumPy)**:\n",
    "  - Color conversions (RGB/BGR/HSV/YCbCr/Gray)\n",
    "  - Geometric transforms (rotate/scale/translate/affine/perspective)\n",
    "  - Filters (Gaussian/Median/Mean) and **Morphology** (dilate/erode/open/close)\n",
    "  - Enhancement (histogram equalization, contrast stretch, sharpening)\n",
    "  - Edge detection (Sobel, Laplacian, Canny)\n",
    "- **Output Layer**: Side-by-side original vs processed preview, status bar (H, W, channels, size), **Save/Download** with compression options.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f14609",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "\n",
    "# Utility to show images inline with Matplotlib\n",
    "def show(img, title=None, cmap=None):\n",
    "    plt.figure()\n",
    "    if img.ndim == 2:\n",
    "        plt.imshow(img, cmap=cmap if cmap is not None else 'gray')\n",
    "    else:\n",
    "        # Matplotlib expects RGB for correct colors\n",
    "        if img.shape[2] == 3:\n",
    "            plt.imshow(img)\n",
    "        else:\n",
    "            # If 4-channel, drop alpha for display\n",
    "            plt.imshow(img[..., :3])\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a54ff2",
   "metadata": {},
   "source": [
    "\n",
    "## 3) Utility Functions (as in the app)\n",
    "\n",
    "These functions mirror the logic in your Streamlit script. We'll re-define them here so we can run demonstrations without the GUI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ea95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def to_uint8(img):\n",
    "    if img.dtype != np.uint8:\n",
    "        img = np.clip(img, 0, 255).astype(np.uint8)\n",
    "    return img\n",
    "\n",
    "def to_pil(img_arr):\n",
    "    img_arr = to_uint8(img_arr)\n",
    "    return Image.fromarray(img_arr)\n",
    "\n",
    "def convert_color(img, mode):\n",
    "    # img expected as RGB for consistency in this notebook\n",
    "    if mode == 'BGR':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "    if mode == 'HSV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    if mode == 'YCbCr':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    if mode == 'GRAY':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return img\n",
    "\n",
    "def rotate_image(img, angle, center=None, scale=1.0):\n",
    "    h, w = img.shape[:2]\n",
    "    if center is None:\n",
    "        center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    return cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "def scale_image(img, fx, fy):\n",
    "    return cv2.resize(img, None, fx=fx, fy=fy, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "def translate_image(img, tx, ty):\n",
    "    M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "    h, w = img.shape[:2]\n",
    "    return cv2.warpAffine(img, M, (w, h))\n",
    "\n",
    "def affine_transform(img, src_pts, dst_pts, dsize=None):\n",
    "    M = cv2.getAffineTransform(np.float32(src_pts), np.float32(dst_pts))\n",
    "    if dsize is None:\n",
    "        h, w = img.shape[:2]\n",
    "        dsize = (w, h)\n",
    "    return cv2.warpAffine(img, M, dsize)\n",
    "\n",
    "def perspective_transform(img, src_pts, dst_pts, dsize=None):\n",
    "    M = cv2.getPerspectiveTransform(np.float32(src_pts), np.float32(dst_pts))\n",
    "    if dsize is None:\n",
    "        h, w = img.shape[:2]\n",
    "        dsize = (w, h)\n",
    "    return cv2.warpPerspective(img, M, dsize)\n",
    "\n",
    "def apply_filter(img, method, ksize=3):\n",
    "    if method == 'gaussian':\n",
    "        return cv2.GaussianBlur(img, (ksize, ksize), 0)\n",
    "    if method == 'median':\n",
    "        return cv2.medianBlur(img, ksize)\n",
    "    if method == 'mean':\n",
    "        return cv2.blur(img, (ksize, ksize))\n",
    "    return img\n",
    "\n",
    "def morphological(img, op, ksize=3):\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (ksize, ksize))\n",
    "    if op == 'dilate':\n",
    "        return cv2.dilate(img, kernel)\n",
    "    if op == 'erode':\n",
    "        return cv2.erode(img, kernel)\n",
    "    if op == 'open':\n",
    "        return cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel)\n",
    "    if op == 'close':\n",
    "        return cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel)\n",
    "    return img\n",
    "\n",
    "def histogram_equalization(img):\n",
    "    if img.ndim == 2:\n",
    "        return cv2.equalizeHist(img)\n",
    "    ycrcb = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    ycrcb[:, :, 0] = cv2.equalizeHist(ycrcb[:, :, 0])\n",
    "    return cv2.cvtColor(ycrcb, cv2.COLOR_YCrCb2RGB)\n",
    "\n",
    "def contrast_stretch(img, in_min=0, in_max=255):\n",
    "    out = (img - in_min) * (255.0 / (in_max - in_min))\n",
    "    return np.clip(out, 0, 255).astype(np.uint8)\n",
    "\n",
    "def sharpen(img):\n",
    "    kernel = np.array([[0, -1, 0], [-1, 5, -1], [0, -1, 0]])\n",
    "    return cv2.filter2D(img, -1, kernel)\n",
    "\n",
    "def sobel_edge(img):\n",
    "    if img.ndim == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    gx = cv2.Sobel(img, cv2.CV_64F, 1, 0, ksize=3)\n",
    "    gy = cv2.Sobel(img, cv2.CV_64F, 0, 1, ksize=3)\n",
    "    mag = np.sqrt(gx ** 2 + gy ** 2)\n",
    "    mag = np.uint8(np.clip(mag / (mag.max() + 1e-8) * 255, 0, 255))\n",
    "    return mag\n",
    "\n",
    "def laplacian_edge(img):\n",
    "    if img.ndim == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    lap = cv2.Laplacian(img, cv2.CV_64F)\n",
    "    lap = np.uint8(np.clip(np.abs(lap) / (np.abs(lap).max() + 1e-8) * 255, 0, 255))\n",
    "    return lap\n",
    "\n",
    "def canny_edge(img, t1, t2):\n",
    "    if img.ndim == 3:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    return cv2.Canny(img, t1, t2)\n",
    "\n",
    "def save_image_bytes(img_arr, fmt='PNG', quality=95):\n",
    "    pil = to_pil(img_arr)\n",
    "    buf = BytesIO()\n",
    "    save_kwargs = {}\n",
    "    if fmt.upper() == 'JPEG':\n",
    "        save_kwargs['format'] = 'JPEG'\n",
    "        save_kwargs['quality'] = quality\n",
    "    else:\n",
    "        save_kwargs['format'] = fmt\n",
    "    pil.save(buf, **save_kwargs)\n",
    "    buf.seek(0)\n",
    "    return buf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4f74fa",
   "metadata": {},
   "source": [
    "\n",
    "## 4) Load a Sample Image (or Generate One)\n",
    "\n",
    "The Streamlit app loads user images. In this notebook, we'll either try to open an example image (if available) or generate a synthetic demo image (checkerboard + gradients) for demonstration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8682acfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def synthetic_demo_image(h=256, w=256):\n",
    "    # Create a simple synthetic RGB image with gradients and a checkerboard\n",
    "    x = np.linspace(0, 255, w, dtype=np.uint8)\n",
    "    y = np.linspace(0, 255, h, dtype=np.uint8)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    checker = (((xv // 32) % 2) ^ ((yv // 32) % 2)) * 255\n",
    "    r = xv\n",
    "    g = yv\n",
    "    b = checker\n",
    "    return np.dstack([r, g, b])\n",
    "\n",
    "# Try to load an existing image from the environment (optional)\n",
    "# Fallback to synthetic image\n",
    "try_paths = [\n",
    "    \"/mnt/data/processed.png\",\n",
    "    \"/mnt/data/Screenshot 2025-09-07 230156.png\",\n",
    "    \"/mnt/data/Screenshot 2025-09-07 230218.png\",\n",
    "    \"/mnt/data/Screenshot 2025-09-07 230412.png\",\n",
    "    \"/mnt/data/Screenshot 2025-09-07 230447.png\",\n",
    "]\n",
    "\n",
    "img = None\n",
    "for p in try_paths:\n",
    "    try:\n",
    "        pil = Image.open(p).convert(\"RGB\")\n",
    "        img = np.array(pil)\n",
    "        break\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "if img is None:\n",
    "    img = synthetic_demo_image()\n",
    "\n",
    "show(img, \"Original (RGB)\")\n",
    "img.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b128eb2",
   "metadata": {},
   "source": [
    "\n",
    "## 5) Color Conversions\n",
    "\n",
    "The app supports: **RGB â†” BGR**, **RGB â†” HSV**, **RGB â†” YCbCr**, **RGB â†” Grayscale**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae3a512",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_hsv = convert_color(img, 'HSV')\n",
    "img_ycbcr = convert_color(img, 'YCbCr')\n",
    "img_gray = convert_color(img, 'GRAY')\n",
    "\n",
    "show(img_hsv, \"HSV\")\n",
    "show(img_ycbcr, \"YCbCr\")\n",
    "show(img_gray, \"Grayscale\", cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8082e871",
   "metadata": {},
   "source": [
    "\n",
    "## 6) Geometric Transformations\n",
    "\n",
    "Rotate, scale, translate, affine, and perspective transforms are used to modify spatial properties of the image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8e7bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rot = rotate_image(img, angle=25)\n",
    "scaled = scale_image(img, fx=0.6, fy=0.6)\n",
    "trans = translate_image(img, tx=40, ty=30)\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "src_aff = np.float32([[0, 0], [w - 1, 0], [0, h - 1]])\n",
    "dst_aff = np.float32([[0, 0], [w - 1, 0], [int(0.2*w), int(0.4*h)]])\n",
    "aff = affine_transform(img, src_aff, dst_aff)\n",
    "\n",
    "src_p = np.float32([[0, 0], [w - 1, 0], [w - 1, h - 1], [0, h - 1]])\n",
    "dst_p = np.float32([[0, int(0.1*h)], [w - 1, 0], [int(0.9*w), h - 1], [int(0.1*w), int(0.9*h)]])\n",
    "persp = perspective_transform(img, src_p, dst_p)\n",
    "\n",
    "show(rot, \"Rotate +25Â°\")\n",
    "show(scaled, \"Scale 0.6x\")\n",
    "show(trans, \"Translate (40, 30)\")\n",
    "show(aff, \"Affine Transform\")\n",
    "show(persp, \"Perspective Transform\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0825601",
   "metadata": {},
   "source": [
    "\n",
    "## 7) Filtering & Morphology\n",
    "\n",
    "- **Filtering**: Gaussian, Median, Mean (Average)  \n",
    "- **Morphology**: Dilate, Erode, Open, Close (on binary/gray images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c98396",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "k = 5\n",
    "gauss = apply_filter(img, 'gaussian', ksize=k)\n",
    "median = apply_filter(img, 'median', ksize=k)\n",
    "mean = apply_filter(img, 'mean', ksize=k)\n",
    "\n",
    "show(gauss, f\"Gaussian Blur (ksize={k})\")\n",
    "show(median, f\"Median Blur (ksize={k})\")\n",
    "show(mean, f\"Mean Blur (ksize={k})\")\n",
    "\n",
    "# Morphology works best on grayscale / binary\n",
    "gray = convert_color(img, 'GRAY')\n",
    "dil = morphological(gray, 'dilate', ksize=5)\n",
    "ero = morphological(gray, 'erode', ksize=5)\n",
    "opn = morphological(gray, 'open', ksize=5)\n",
    "cls = morphological(gray, 'close', ksize=5)\n",
    "\n",
    "show(dil, \"Dilation (gray)\", cmap='gray')\n",
    "show(ero, \"Erosion (gray)\", cmap='gray')\n",
    "show(opn, \"Opening (gray)\", cmap='gray')\n",
    "show(cls, \"Closing (gray)\", cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db550cb0",
   "metadata": {},
   "source": [
    "\n",
    "## 8) Enhancement & Edge Detection\n",
    "\n",
    "- **Enhancement**: Histogram Equalization, Contrast Stretching, Sharpening  \n",
    "- **Edges**: Sobel, Laplacian, Canny\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74666626",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eq = histogram_equalization(img)\n",
    "cs = contrast_stretch(img, in_min=20, in_max=235)  # demo thresholds\n",
    "sh = sharpen(img)\n",
    "\n",
    "sob = sobel_edge(img)\n",
    "lap = laplacian_edge(img)\n",
    "can = canny_edge(img, 100, 200)\n",
    "\n",
    "show(eq, \"Histogram Equalization (Y channel)\")\n",
    "show(cs, \"Contrast Stretch\")\n",
    "show(sh, \"Sharpen\")\n",
    "show(sob, \"Sobel Edge (magnitude)\", cmap='gray')\n",
    "show(lap, \"Laplacian Edge\", cmap='gray')\n",
    "show(can, \"Canny Edge\", cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b06e1842",
   "metadata": {},
   "source": [
    "\n",
    "## 9) Saving with Compression (PNG / JPEG / BMP)\n",
    "\n",
    "The app lets you save processed images with different formats and compare sizes. Below we simulate saving to bytes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaa3602",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "buf_png = save_image_bytes(img, fmt='PNG')\n",
    "buf_jpg = save_image_bytes(img, fmt='JPEG', quality=80)\n",
    "buf_bmp = save_image_bytes(img, fmt='BMP')\n",
    "\n",
    "sizes = {\n",
    "    \"PNG bytes\": len(buf_png.getvalue()),\n",
    "    \"JPEG bytes (q=80)\": len(buf_jpg.getvalue()),\n",
    "    \"BMP bytes\": len(buf_bmp.getvalue())\n",
    "}\n",
    "sizes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "266db84e",
   "metadata": {},
   "source": [
    "\n",
    "## 10) How the Streamlit UI Maps to These Functions\n",
    "\n",
    "- **Sidebar Inputs** (selectboxes, sliders, checkboxes) choose the operation and its parameters.  \n",
    "- The app reads your file via `st.file_uploader`, then calls the corresponding functions (e.g., `rotate_image`, `apply_filter`, `canny_edge`).  \n",
    "- **Display** uses `st.image` for **Original** (left) and **Processed** (right).  \n",
    "- **Status Bar** shows dimensions, channels, format, file size.  \n",
    "- **Save / Export** uses `BytesIO` to create downloadable images in your chosen format (PNG/JPEG/BMP).  \n",
    "- **Webcam Mode**: A loop reads frames from `cv2.VideoCapture(0)`, converts to RGB, applies optional operations (e.g., Canny), and displays frames live.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8fd9ee",
   "metadata": {},
   "source": [
    "\n",
    "## 11) Troubleshooting\n",
    "\n",
    "- **`ModuleNotFoundError: No module named 'streamlit'`**  \n",
    "  Install Streamlit in your active environment:  \n",
    "  ```bash\n",
    "  pip install streamlit\n",
    "  ```\n",
    "\n",
    "- **`streamlit` not recognized as a command (Windows)**  \n",
    "  Run via the Python module to avoid PATH issues:  \n",
    "  ```bash\n",
    "  python -m streamlit run app.py\n",
    "  ```\n",
    "\n",
    "- **Webcam not opening**  \n",
    "  - Make sure a webcam is available and not used by another app.  \n",
    "  - Try index `1` instead of `0`: `cv2.VideoCapture(1)`.\n",
    "\n",
    "- **Slow performance**  \n",
    "  - Work with resized images during experiments.  \n",
    "  - Prefer smaller kernel sizes and fewer chained operations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a582689",
   "metadata": {},
   "source": [
    "\n",
    "## 12) Try-It-Yourself Exercises\n",
    "\n",
    "1. Add **Bilateral Filter** to the filtering section and compare with Gaussian/Median.  \n",
    "2. Add **Unsharp Masking** for sharpening with a tunable amount and radius.  \n",
    "3. Build a **split-view overlay** using NumPy slicing (left = original, right = processed).  \n",
    "4. Extend **webcam mode** to toggle multiple operations at once (e.g., sharpen + Canny).  \n",
    "5. Add **bitwise operations** (AND/OR/XOR/NOT) with a synthetic mask to the app and test them.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
