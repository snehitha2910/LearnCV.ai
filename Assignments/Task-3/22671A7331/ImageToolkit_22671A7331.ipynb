{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9563b8f4",
   "metadata": {},
   "source": [
    "# ImageToolkit Notebook â€” Roll 22671A7331\n",
    "\n",
    "This notebook accompanies the Streamlit app and the detailed PDF report. It contains runnable code and explanations for each processing step.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c5b138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: imports. Run this cell to prepare.\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helper to show images inline\n",
    "def show(img, title=None):\n",
    "    if img is None:\n",
    "        print('None image')\n",
    "        return\n",
    "    if isinstance(img, np.ndarray):\n",
    "        if img.ndim == 2:\n",
    "            plt.imshow(img, cmap='gray')\n",
    "        else:\n",
    "            # assume BGR (OpenCV) -> convert to RGB for display\n",
    "            plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    else:\n",
    "        plt.imshow(img)\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87fe53b",
   "metadata": {},
   "source": [
    "## Example Image\n",
    "We'll create a synthetic image for experiments (so the notebook runs without external files)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2fd1872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a synthetic test image (512x512) with gradients and shapes\n",
    "def make_synthetic_image(w=512, h=512):\n",
    "    x = np.linspace(0, 255, w, dtype=np.uint8)\n",
    "    y = np.linspace(0, 255, h, dtype=np.uint8)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    b = xv\n",
    "    g = yv\n",
    "    r = ((xv.astype(np.uint16) + yv.astype(np.uint16)) // 2).astype(np.uint8)\n",
    "    img = np.stack([b, g, r], axis=2)\n",
    "    cv2.circle(img, (w//2, h//2), min(w,h)//6, (255,255,255), thickness=-1)\n",
    "    cv2.rectangle(img, (10,10), (w-10, h//4), (0,0,0), thickness=-1)\n",
    "    return img\n",
    "\n",
    "img = make_synthetic_image(512, 512)\n",
    "show(img, 'Synthetic Test Image')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6b820f",
   "metadata": {},
   "source": [
    "## Color Space Conversions\n",
    "Convert between BGR, Grayscale, HSV, and YCrCb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d845d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "show(gray, 'Grayscale')\n",
    "\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "show(hsv, 'HSV (displayed as RGB - not perceptual)')\n",
    "\n",
    "ycrcb = cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "show(ycrcb, 'YCrCb (displayed as RGB - not perceptual)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c62cf6",
   "metadata": {},
   "source": [
    "## Filtering & Morphology\n",
    "Gaussian, Median, Mean filtering and morphological operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8648af2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gblur = cv2.GaussianBlur(img, (7,7), 0)\n",
    "show(gblur, 'Gaussian Blur (7x7)')\n",
    "\n",
    "median = cv2.medianBlur(img, 7)\n",
    "show(median, 'Median (7)')\n",
    "\n",
    "mean = cv2.blur(img, (7,7))\n",
    "show(mean, 'Mean filter (7x7)')\n",
    "\n",
    "# Morphology on grayscale edges\n",
    "edges = cv2.Canny(gray, 50, 150)\n",
    "show(edges, 'Canny edges')\n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "dilated = cv2.dilate(edges, kernel, iterations=1)\n",
    "show(dilated, 'Dilated edges')\n",
    "\n",
    "eroded = cv2.erode(edges, kernel, iterations=1)\n",
    "show(eroded, 'Eroded edges')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f1c258",
   "metadata": {},
   "source": [
    "## Enhancement\n",
    "Histogram equalization and contrast stretching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6aff7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "heq = cv2.equalizeHist(gray)\n",
    "show(heq, 'Histogram Equalized (grayscale)')\n",
    "\n",
    "# Contrast stretching example (linear between percentiles)\n",
    "p2, p98 = np.percentile(img, (2, 98))\n",
    "stretched = np.clip((img - p2) * 255.0 / (p98 - p2), 0, 255).astype(np.uint8)\n",
    "show(stretched, 'Contrast Stretched')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "197bef40",
   "metadata": {},
   "source": [
    "## Edge Detection\n",
    "Sobel, Laplacian, and Canny examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d048959",
   "metadata": {},
   "outputs": [],
   "source": [
    "sobx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "soby = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "mag = np.sqrt(sobx**2 + soby**2)\n",
    "mag = np.uint8(np.clip(mag / mag.max() * 255, 0, 255))\n",
    "show(mag, 'Sobel Magnitude')\n",
    "\n",
    "lap = cv2.Laplacian(gray, cv2.CV_64F)\n",
    "lap = np.uint8(np.clip(np.abs(lap), 0, 255))\n",
    "show(lap, 'Laplacian')\n",
    "\n",
    "canny = cv2.Canny(gray, 50, 150)\n",
    "show(canny, 'Canny (50,150)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a32b0b",
   "metadata": {},
   "source": [
    "## Compression & Saving\n",
    "Save outputs in different formats and compare file sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff3ff94",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/mnt/data'\n",
    "import os\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "def save_and_report(img, name, fmt='PNG', quality=90):\n",
    "    fname = os.path.join(out_dir, f'notebook_22671A7331_' + name + '.' + fmt.lower())\n",
    "    # convert to PIL for saving convenience\n",
    "    if isinstance(img, np.ndarray):\n",
    "        if img.ndim == 3:\n",
    "            pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        else:\n",
    "            pil = Image.fromarray(img)\n",
    "    else:\n",
    "        pil = img\n",
    "    if fmt.lower() in ('jpg','jpeg'):\n",
    "        pil.save(fname, format='JPEG', quality=quality)\n",
    "    else:\n",
    "        pil.save(fname, format=fmt.upper())\n",
    "    size = os.path.getsize(fname)\n",
    "    print(f'Saved {fname} -> {size} bytes')\n",
    "    return fname, size\n",
    "\n",
    "save_and_report(img, 'original', fmt='PNG')\n",
    "save_and_report(img, 'original_jpeg', fmt='JPEG', quality=85)\n",
    "save_and_report(img, 'original_bmp', fmt='BMP')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05b7882",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook and the Streamlit app illustrate core techniques in image processing. Modify parameters and try with real images to learn more."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
