{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "597372d6",
   "metadata": {},
   "source": [
    "# üñºÔ∏è ImageToolkit - Step by Step with OpenCV\n",
    "\n",
    "This notebook demonstrates various **image processing operations** implemented in your `CVToolkit` Streamlit app, but in a Jupyter-friendly format. We'll cover color conversions, transformations, filters, enhancements, and edge detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa717f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Utility function to show images\n",
    "def show(img, cmap=None, title=\"\"):\n",
    "    plt.figure(figsize=(5,5))\n",
    "    if len(img.shape) == 2:\n",
    "        plt.imshow(img, cmap=cmap)\n",
    "    else:\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ae570b",
   "metadata": {},
   "source": [
    "## Step 1: Load and Display Image\n",
    "Upload or read an image using OpenCV/PIL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db875dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('sample.jpg')  # replace with your image path\n",
    "show(img, title=\"Original Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b78580",
   "metadata": {},
   "source": [
    "## Step 2: Color Conversions\n",
    "We can convert images to different color spaces or apply filters like sepia/invert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "show(gray, cmap='gray', title=\"Grayscale\")\n",
    "\n",
    "# HSV\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "show(hsv, title=\"HSV\")\n",
    "\n",
    "# Sepia filter\n",
    "sepia_kernel = np.array([[0.272, 0.534, 0.131],\n",
    "                         [0.349, 0.686, 0.168],\n",
    "                         [0.393, 0.769, 0.189]])\n",
    "sepia = cv2.transform(img, sepia_kernel)\n",
    "sepia = np.clip(sepia,0,255).astype(np.uint8)\n",
    "show(sepia, title=\"Sepia\")\n",
    "\n",
    "# Invert colors\n",
    "inverted = cv2.bitwise_not(img)\n",
    "show(inverted, title=\"Inverted Colors\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752e8ea9",
   "metadata": {},
   "source": [
    "## Step 3: Geometric Transformations\n",
    "Rotate, scale, translate, or flip images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc27f4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotation\n",
    "(h, w) = img.shape[:2]\n",
    "M = cv2.getRotationMatrix2D((w//2, h//2), 45, 1.0)\n",
    "rotated = cv2.warpAffine(img, M, (w, h))\n",
    "show(rotated, title=\"Rotated 45¬∞\")\n",
    "\n",
    "# Scaling\n",
    "scaled = cv2.resize(img, None, fx=1.5, fy=1.5)\n",
    "show(scaled, title=\"Scaled 1.5x\")\n",
    "\n",
    "# Translation\n",
    "M = np.float32([[1,0,50],[0,1,30]])\n",
    "translated = cv2.warpAffine(img, M, (w, h))\n",
    "show(translated, title=\"Translated (50,30)\")\n",
    "\n",
    "# Flipping\n",
    "flipped = cv2.flip(img, 1)\n",
    "show(flipped, title=\"Flipped Horizontally\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4c9e4f",
   "metadata": {},
   "source": [
    "## Step 4: Filters & Enhancement\n",
    "We can apply Gaussian blur, sharpening, and histogram equalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94f456b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gaussian Blur\n",
    "blur = cv2.GaussianBlur(img,(11,11),0)\n",
    "show(blur, title=\"Gaussian Blur\")\n",
    "\n",
    "# Sharpening\n",
    "kernel = np.array([[0,-1,0],[-1,5,-1],[0,-1,0]])\n",
    "sharp = cv2.filter2D(img, -1, kernel)\n",
    "show(sharp, title=\"Sharpened\")\n",
    "\n",
    "# Histogram Equalization (on grayscale)\n",
    "equalized = cv2.equalizeHist(gray)\n",
    "show(equalized, cmap='gray', title=\"Histogram Equalization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1a9fed",
   "metadata": {},
   "source": [
    "## Step 5: Edge Detection\n",
    "Detect edges using Sobel and Canny methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dd5f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sobel Edge Detection\n",
    "sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "sobel = np.sqrt(sobelx**2 + sobely**2)\n",
    "sobel = np.clip(sobel,0,255).astype(np.uint8)\n",
    "show(sobel, cmap='gray', title=\"Sobel Edge\")\n",
    "\n",
    "# Canny Edge Detection\n",
    "canny = cv2.Canny(gray,100,200)\n",
    "show(canny, cmap='gray', title=\"Canny Edge\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12879f41",
   "metadata": {},
   "source": [
    "## ‚úÖ Conclusion & Practice\n",
    "We explored:\n",
    "- Color Conversions (Grayscale, HSV, Sepia, Invert)\n",
    "- Transformations (Rotate, Scale, Translate, Flip)\n",
    "- Filters (Blur, Sharpen, Histogram Equalization)\n",
    "- Edge Detection (Sobel, Canny)\n",
    "\n",
    "**Practice Ideas:**\n",
    "- Try different rotation angles.\n",
    "- Change Gaussian blur kernel size.\n",
    "- Use different thresholds for Canny edge detection.\n",
    "- Chain multiple operations together (e.g., blur ‚Üí edge detection)."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
